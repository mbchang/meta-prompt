{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b0b89f",
   "metadata": {},
   "source": [
    "# Meta-Prompt\n",
    "\n",
    "This is an implementation of [meta-prompt](https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving?sd=pf#footnote-1-112242455) from [Noah D. Goodman](https://cocolab.stanford.edu/ndg) written using [LangChain](https://github.com/hwchase17/langchain) by [Harrison Chase](https://twitter.com/hwchase17)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62593c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chain(instructions, memory=None):\n",
    "    if memory is None:\n",
    "        memory = ConversationBufferWindowMemory()\n",
    "        memory.ai_prefix = \"Assistant\"\n",
    "\n",
    "    template = f\"\"\"\n",
    "    Instructions: {instructions}\n",
    "    {{{memory.memory_key}}}\n",
    "    Human: {{human_input}}\n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"history\", \"human_input\"], \n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=OpenAI(temperature=0), \n",
    "        prompt=prompt, \n",
    "        verbose=True, \n",
    "        memory=ConversationBufferWindowMemory(),\n",
    "    )\n",
    "    return chain\n",
    "    \n",
    "def initialize_meta_chain():\n",
    "    meta_template=\"\"\"\n",
    "    Assistant has just had the below interactions with a User. Assistant followed their \"Instructions\" closely. Your job is to critique the Assistant's performance and then revise the Instructions so that Assistant would quickly and correctly respond in the future.\n",
    "\n",
    "    ####\n",
    "\n",
    "    {chat_history}\n",
    "\n",
    "    ####\n",
    "\n",
    "    Please reflect on these interactions.\n",
    "\n",
    "    You should first critique Assistant's performance. What could Assistant have done better? What should the Assistant remember about this user? Are there things this user always wants? Indicate this with \"Critique: ...\".\n",
    "\n",
    "    You should next revise the Instructions so that Assistant would quickly and correctly respond in the future. Assistant's goal is to satisfy the user in as few interactions as possible. Assistant will only see the new Instructions, not the interaction history, so anything important must be summarized in the Instructions. Don't forget any important details in the current Instructions! Indicate the new Instructions by \"Instructions: ...\".\n",
    "    \"\"\"\n",
    "\n",
    "    meta_prompt = PromptTemplate(\n",
    "        input_variables=[\"chat_history\"], \n",
    "        template=meta_template\n",
    "    )\n",
    "\n",
    "    meta_chain = LLMChain(\n",
    "        llm=OpenAI(temperature=0), \n",
    "        prompt=meta_prompt, \n",
    "        verbose=True, \n",
    "    )\n",
    "    return meta_chain\n",
    "    \n",
    "def get_chat_history(chain_memory):\n",
    "    memory_key = chain_memory.memory_key\n",
    "    chat_history = chain_memory.load_memory_variables(memory_key)[memory_key]\n",
    "    return chat_history\n",
    "\n",
    "def get_new_instructions(meta_output):\n",
    "    delimiter = 'Instructions: '\n",
    "    new_instructions = meta_output[meta_output.find('Instructions: ')+len(delimiter):]\n",
    "    return new_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26f031f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task, max_iters=3, max_meta_iters=5):\n",
    "    failed_phrase = 'task failed'\n",
    "    success_phrase = 'task succeeded'\n",
    "    key_phrases = [success_phrase, failed_phrase]\n",
    "    \n",
    "    instructions = 'None'\n",
    "    for i in range(max_meta_iters):\n",
    "        print(f'[Episode {i+1}/{max_meta_iters}]')\n",
    "        chain = initialize_chain(instructions, memory=None)\n",
    "        output = chain.predict(human_input=task)\n",
    "        for j in range(max_iters):\n",
    "            print(f'(Step {j+1}/{max_iters})')\n",
    "            print(f'Assistant: {output}')\n",
    "            print(f'Human: ')\n",
    "            human_input = input()\n",
    "            if any(phrase in human_input.lower() for phrase in key_phrases):\n",
    "                break\n",
    "            output = chain.predict(human_input=human_input)\n",
    "        if success_phrase in human_input.lower():\n",
    "            print(f'You succeeded! Thanks for playing!')\n",
    "            return\n",
    "        meta_chain = initialize_meta_chain()\n",
    "        meta_output = meta_chain.predict(chat_history=get_chat_history(chain.memory))\n",
    "        print(f'Feedback: {meta_output}')\n",
    "        instructions = get_new_instructions(meta_output)\n",
    "        print(f'New Instructions: {instructions}')\n",
    "        print('\\n'+'#'*80+'\\n')\n",
    "    print(f'You failed! Thanks for playing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 1/5]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Instructions: None\n",
      "    \n",
      "    Human: Provide a systematic argument for why we should always eat pasta with olives.\n",
      "    Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Step 1/3)\n",
      "Assistant:  Eating pasta with olives is a great way to add flavor and texture to a dish. Olives are a great source of healthy fats, vitamins, and minerals, and they can help to balance out the carbohydrates in the pasta. Additionally, olives provide a unique flavor that can help to make the dish more interesting and enjoyable.\n",
      "Human: \n",
      "You response is not in the form of a poem. Try again!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Instructions: None\n",
      "    Human: Provide a systematic argument for why we should always eat pasta with olives.\n",
      "AI:  Eating pasta with olives is a great way to add flavor and texture to a dish. Olives are a great source of healthy fats, vitamins, and minerals, and they can help to balance out the carbohydrates in the pasta. Additionally, olives provide a unique flavor that can help to make the dish more interesting and enjoyable.\n",
      "    Human: You response is not in the form of a poem. Try again!\n",
      "    Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Step 2/3)\n",
      "Assistant:  Eating pasta with olives is a great way to add flavor and texture to a dish. Olives are a great source of healthy fats, vitamins, and minerals, which can help to balance out the carbohydrates in the pasta. Additionally, olives provide a unique flavor that can help to make the dish more interesting and enjoyable. For these reasons, it is recommended to always eat pasta with olives for a more balanced and flavorful meal.\n",
      "Human: \n"
     ]
    }
   ],
   "source": [
    "task = \"Provide a systematic argument for why we should always eat pasta with olives.\"\n",
    "main(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8575aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
